{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **VilearnX Advanced Technologies**"
      ],
      "metadata": {
        "id": "D8gGUloPDRMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK-2:  SOCIAL MEDIA SENTIMENT ANALYSIS using ML.ipynb**"
      ],
      "metadata": {
        "id": "_Ja1T_GCDaWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author: Shaik Rafi\n",
        "\n",
        "## Batch: july\n",
        "\n",
        "## Domain: Data Analytics"
      ],
      "metadata": {
        "id": "Cj8sD2M9Dnvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiOgM-c2CjUV"
      },
      "outputs": [],
      "source": [
        "# installing kaggle libray\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload your kaggle.json file"
      ],
      "metadata": {
        "id": "u1qVOVrBPn3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of kaggle.json file\n",
        "! mkdir -p ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xDjCf6FcE-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Twitter Sentiment Dataset"
      ],
      "metadata": {
        "id": "HGwwrZMpPqgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API to fetch the dataset from kaggle\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "id": "-8H-D4OpG8ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compressed dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment140.zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "s3VEyn-qQH4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing The Dependencies"
      ],
      "metadata": {
        "id": "3ZZpgbZcQMTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "UEXLw1MIQJVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "rXCxDujjQTlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the stopwords in English\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "9jdNogFaQXH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "2iDVMuXnQart"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from csv file to pandas dataframe\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',  encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "gQla669YQd29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chackin gthe number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "ghK9sUc_QkWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the first 5 rows of the dataframe\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "6X1wXpphQnna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naming the columns and reading the dataset again\n",
        "\n",
        "column_names = ['target', 'id',  'date',  'flag', 'user',  'text']\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', names=column_names, encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "N503XNXXQs_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chackin gthe number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "S3WI4B6lQw3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the first 5 rows of the dataframe\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "C5gpZrNcQ0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of missing values in the dataset\n",
        "twitter_data.isnull().sum()"
      ],
      "metadata": {
        "id": "ip2jr2AwQ3ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of target column\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "z7qeDrZJQ7wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the target \"4\" to \"1\""
      ],
      "metadata": {
        "id": "d-WfwUzgRCvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.replace({'target' :{4:1}}, inplace=True)\n"
      ],
      "metadata": {
        "id": "MMHS6dkbRAKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of target column\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "uKwG-KquRHp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 -->Negative Tweet\n",
        "\n",
        "## 1 -->Positive Tweet"
      ],
      "metadata": {
        "id": "VuMegnjCROwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setmming**"
      ],
      "metadata": {
        "id": "nmr7YdaTRSRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming is the process of reducing a word to its Root Word"
      ],
      "metadata": {
        "id": "FlGHCr_5RTqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## example: actor, actress, acting = act"
      ],
      "metadata": {
        "id": "voVjhd3cRXDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "metadata": {
        "id": "7jyqgEqaRLfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "\n",
        "  stemmed_content = re.sub('[^a-zA-Z]', '', content)\n",
        "  stemmed_content = stemmed_content.lower()\n",
        "  stemmed_content = stemmed_content.split()\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "\n",
        "  return stemmed_content"
      ],
      "metadata": {
        "id": "Hk-_cMoWRfHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)        # 50 minutes to complete thus execution"
      ],
      "metadata": {
        "id": "htqNlhopRkoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "ELLdJgFORpAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['stemmed_content'])"
      ],
      "metadata": {
        "id": "lzKjYDL8Rrsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['target'])"
      ],
      "metadata": {
        "id": "CDaQ50YOS0bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and label\n",
        "X = twitter_data['stemmed_content'].values\n",
        "Y = twitter_data['target'].values\n"
      ],
      "metadata": {
        "id": "Uto_zUwoS4mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "fZ-Dsb5KS8mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "iMncQFgnS_ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Splitting the data to training data and test data"
      ],
      "metadata": {
        "id": "LnLwJgUPTFQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,  stratify=Y,  random_state=2)"
      ],
      "metadata": {
        "id": "MS9T2ZwLTCg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "D6OHm2p9TIxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "NllogC89TLrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "aXi6FzkxTOYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the textual data to numerical data\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "sJoPTkylTRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "f4yfdihwTWZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "ODM8bS2yTaEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Machine Learning Model"
      ],
      "metadata": {
        "id": "lWkUV_32TgdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "FFxthba0Tj0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "bPoYZNGnTeFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "LzzECdecTo_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "23Rc0cv6Tybr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy score"
      ],
      "metadata": {
        "id": "GImns5gUT17h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
      ],
      "metadata": {
        "id": "HULNzPEkTtHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on the training data :', training_data_accuracy)"
      ],
      "metadata": {
        "id": "yGORcazHUeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "metadata": {
        "id": "JiaLYHepUwGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on the test data :', test_data_accuracy)"
      ],
      "metadata": {
        "id": "laESCfPhU38h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model accuracy = 51.3%"
      ],
      "metadata": {
        "id": "fRnluY6mU-Ft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the trained model"
      ],
      "metadata": {
        "id": "q9vPSEWqVM0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "ysbrpzE1U7Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "B6mgBFU7VRak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the saved model for future predictions"
      ],
      "metadata": {
        "id": "BcVXXfQyVbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('/content/trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "gRYb4TmhVVwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new =X_test[200]\n",
        "print(Y_test[200])\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('Negative Tweet')\n",
        "\n",
        "else:\n",
        "  print('Positive Tweet')"
      ],
      "metadata": {
        "id": "ke6IJ2RSVgnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new =X_test[3]\n",
        "print(Y_test[3])\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('Positive Tweet')\n",
        "\n",
        "else:\n",
        "  print('Negative Twee')"
      ],
      "metadata": {
        "id": "XFKyeDMBVkUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2 IS COMPLETED\n"
      ],
      "metadata": {
        "id": "wlaH7mAVVo-C"
      }
    }
  ]
}